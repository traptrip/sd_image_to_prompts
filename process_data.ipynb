{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_only(string):\n",
    "    for s in string:\n",
    "        cat = unicodedata.category(s)         \n",
    "        if not cat in ['Ll', 'Lu', 'Nd', 'Po', 'Pd', 'Zs']:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base data size:  81910\n",
      "After `filter NaNs`:  81910\n",
      "After `filter small`:  81807\n",
      "After `filter not Eng`:  77602\n",
      "After `filter duplicates`:  5465\n",
      "Filtered data size:  5465\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/sd2_data/metadata.csv\")\n",
    "\n",
    "print(\"Base data size: \", df.shape[0])\n",
    "\n",
    "# Only 512x512 images\n",
    "# df = df[(df['width'] == 512) & (df['height'] == 512)]\n",
    "\n",
    "# Strip prompts\n",
    "df['prompt'] = df['prompt'].str.strip()\n",
    "\n",
    "# Filter NaN prompts\n",
    "df = df[~df['prompt'].str.contains('^(?:\\s*|NULL|null|NaN)$', na=True)]\n",
    "print(\"After `filter NaNs`: \", df.shape[0])\n",
    "\n",
    "# Filter too small prompts\n",
    "df = df[df['prompt'].map(lambda x: len(x.split())) >= 5]\n",
    "print(\"After `filter small`: \", df.shape[0])\n",
    "\n",
    "# Filter not English prompts\n",
    "df = df[df['prompt'].apply(is_english_only)]\n",
    "print(\"After `filter not Eng`: \", df.shape[0])\n",
    " \n",
    "# Filter head & tail duplicates\n",
    "df['head'] = df['prompt'].str[:15]\n",
    "df['tail'] = df['prompt'].str[-15:]\n",
    "df.drop_duplicates(subset='head', inplace=True)\n",
    "df.drop_duplicates(subset='tail', inplace=True)\n",
    "print(\"After `filter duplicates`: \", df.shape[0])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Filtered data size: \", df.shape[0])\n",
    "\n",
    "df.to_csv(\"data/sd2_data/metadata_clean.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD_DB2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_parquet(\"/drives/drive4/competitions/SD/metadata.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base data size:  2000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1162164/2676352817.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  metadata[\"image_name\"] = metadata[\"image_name\"].str.replace(\".png\", \".jpg\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only existed images:  2000000\n"
     ]
    }
   ],
   "source": [
    "# filter exist images\n",
    "# images_names = [p.name for p in Path(\"/drives/drive4/competitions/SD/images/\").iterdir()]\n",
    "# images_names += [p.name for p in Path(\"/drives/drive2/competitions/SD/images/\").iterdir()]\n",
    "\n",
    "print(\"Base data size: \", metadata.shape[0])\n",
    "images_paths = list(Path(\"./data/sd_data_resize224/images\").rglob(\"*.jpg\"))\n",
    "images_names = [p.name for p in images_paths]\n",
    "metadata[\"image_name\"] = metadata[\"image_name\"].str.replace(\".png\", \".jpg\")\n",
    "\n",
    "metadata = metadata[metadata.image_name.isin(images_names)]\n",
    "tmp = pd.DataFrame({\"path\": images_paths})\n",
    "tmp[\"image_name\"] = tmp.path.apply(lambda p: p.name)\n",
    "metadata = metadata.merge(tmp, on=\"image_name\")\n",
    "\n",
    "print(\"Only existed images: \", metadata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base size:  2000000\n",
      "After `filter size`:  1057211\n",
      "After `filter NaNs`:  1056685\n",
      "After `filter small`:  962590\n",
      "After `filter not Eng`:  913481\n",
      "After `filter steps=0`:  913466\n",
      "Filtered data size:  913466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1162164/3429192514.py:46: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  m[\"image_name\"] = m[\"image_name\"].str.replace(\".png\", \".jpg\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data size:  913466\n"
     ]
    }
   ],
   "source": [
    "df = metadata.copy()\n",
    "print(\"Base size: \", df.shape[0])\n",
    "\n",
    "# Only 512x512 images\n",
    "df = df[((df['width']== 512) & (df['height'] == 512)) | ((df['width']== 768) & (df['height'] == 768))]\n",
    "print(\"After `filter size`: \", df.shape[0])\n",
    "\n",
    "# Strip prompts\n",
    "df['prompt'] = df['prompt'].str.strip()\n",
    "\n",
    "# Filter NaN prompts\n",
    "df = df[~df['prompt'].str.contains('^(?:\\s*|NULL|null|NaN)$', na=True)]\n",
    "print(\"After `filter NaNs`: \", df.shape[0])\n",
    "\n",
    "# Filter too small prompts\n",
    "df = df[df['prompt'].map(lambda x: len(x.split())) >= 5]\n",
    "print(\"After `filter small`: \", df.shape[0])\n",
    "\n",
    "# Filter not English prompts\n",
    "df = df[df['prompt'].apply(is_english_only)]\n",
    "print(\"After `filter not Eng`: \", df.shape[0])\n",
    "\n",
    "# Filter steps\n",
    "df = df[df['step'] > 0]\n",
    "print(\"After `filter steps=0`: \", df.shape[0])\n",
    "\n",
    "\n",
    "# # Filter head & tail duplicates\n",
    "# df['head'] = df['prompt'].str[:20]\n",
    "# df['tail'] = df['prompt'].str[-20:]\n",
    "# df.drop_duplicates(subset='head', inplace=True)\n",
    "# df.drop_duplicates(subset='tail', inplace=True)\n",
    "# print(\"After `filter duplicates`: \", df.shape[0])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Filtered data size: \", df.shape[0])\n",
    "\n",
    "# train_idxs, test_idxs = train_test_split(df.index, test_size=0.05, random_state=42)\n",
    "# print(f\"Train: {len(train_idxs)} Test: {len(test_idxs)}\")\n",
    "# df.loc[train_idxs, \"stage\"] = \"train\"\n",
    "# df.loc[test_idxs, \"stage\"] = \"test\"\n",
    "m = pd.read_csv(\"data/sd_data/metadata.csv\")\n",
    "m = m.loc[m.stage == \"test\"].reset_index(drop=True)\n",
    "m = m[[\"image_name\", \"stage\"]]\n",
    "m[\"image_name\"] = m[\"image_name\"].str.replace(\".png\", \".jpg\")\n",
    "df = df.merge(m, \"left\", on=\"image_name\")\n",
    "df[\"stage\"] = df[\"stage\"].fillna(\"train\")\n",
    "\n",
    "print(\"Filtered data size: \", df.shape[0])\n",
    "\n",
    "df.to_csv(\"./metadata_sd2b_resize224.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./metadata_sd2b_resize224.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3d7bc80714472584560869d0bc3f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cuda\")\n",
    "embeddings = st_model.encode(df.prompt.values, batch_size=1024, normalize_embeddings=False, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.from_numpy(embeddings), \"embeddings.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bf5e411ee04b23bb9465450240235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/913466 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(idxs_to_ignore)\n\u001b[0;32m---> 27\u001b[0m IGNORING \u001b[39m=\u001b[39m get_ignoring_idxs(embeddings)\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36mget_ignoring_idxs\u001b[0;34m(embeddings, batch_size, thresh)\u001b[0m\n\u001b[1;32m     16\u001b[0m cos_sim \u001b[39m=\u001b[39m cosine_similarity(embeddings[idxs], embeddings)\n\u001b[1;32m     17\u001b[0m np\u001b[39m.\u001b[39mfill_diagonal(cos_sim, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m new_to_ignore \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(np\u001b[39m.\u001b[39;49mnonzero(cos_sim \u001b[39m>\u001b[39;49m thresh)[\u001b[39m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m idxs_to_ignore \u001b[39m=\u001b[39m idxs_to_ignore\u001b[39m.\u001b[39munion(new_to_ignore)\n\u001b[1;32m     20\u001b[0m pbar\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(idxs))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/sd/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1958\u001b[0m, in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_nonzero_dispatcher)\n\u001b[1;32m   1867\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnonzero\u001b[39m(a):\n\u001b[1;32m   1868\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m    Return the indices of the elements that are non-zero.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1956\u001b[0m \n\u001b[1;32m   1957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1958\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mnonzero\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/sd/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# filter.py\n",
    "\n",
    "def get_ignoring_idxs(embeddings, batch_size=1024, thresh=0.95):\n",
    "    bs = batch_size\n",
    "    n_embeddings = len(embeddings)\n",
    "    idxs_to_ignore = set()\n",
    "    pbar = tqdm(total=n_embeddings)\n",
    "    i = 0\n",
    "    while i < n_embeddings:\n",
    "        idxs = []\n",
    "        while len(idxs) < bs and i < n_embeddings:\n",
    "            if i not in idxs_to_ignore:\n",
    "                idxs.append(i)\n",
    "            i += 1\n",
    "        cos_sim = cosine_similarity(embeddings[idxs], embeddings)\n",
    "        np.fill_diagonal(cos_sim, 0)\n",
    "        new_to_ignore = set(np.nonzero(cos_sim > thresh)[1])\n",
    "        idxs_to_ignore = idxs_to_ignore.union(new_to_ignore)\n",
    "        pbar.update(len(idxs))\n",
    "        \n",
    "    del embeddings\n",
    "    gc.collect()\n",
    "    \n",
    "    return list(idxs_to_ignore)\n",
    "\n",
    "IGNORING = get_ignoring_idxs(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(list(dropped)), \"duplicates_idxs_sd_2b.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped = torch.load(\"dropped_idxs.pth\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[~df.index.isin(dropped)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900539, 642738)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], filtered_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(\"./metadata_sd2b_resize224_filtered_similar.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_names1 = [p.name for p in Path(\"/drives/drive4/competitions/SD/images/\").iterdir()]\n",
    "# images_names2 = [p.name for p in Path(\"/drives/drive2/competitions/SD/images/\").iterdir()]\n",
    "filtered_df.loc[filtered_df.image_name.isin(images_names1), \"path\"] = (\"/drives/drive4/competitions/SD/images/\" + filtered_df.loc[filtered_df.image_name.isin(images_names1), \"image_name\"]).values\n",
    "filtered_df.loc[filtered_df.image_name.isin(images_names2), \"path\"] = \"/drives/drive2/competitions/SD/images/\" + (filtered_df.loc[filtered_df.image_name.isin(images_names2), \"image_name\"]).values\n",
    "\n",
    "filtered_df.to_csv(\"./metadata_sd2b_filtered_similar.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check prompts similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6388701]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2', device=\"cuda\")\n",
    "\n",
    "p1 = \"photorealistic, 8k, superresolution art of trump riding motocross\"\n",
    "p2 = \"photorealistic, 8k, superresolution art of girl riding a horse\"\n",
    "\n",
    "e1 = st_model.encode(p1)[None]\n",
    "e2 = st_model.encode(p2)[None]\n",
    "\n",
    "cosine_similarity(e1, e2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323614"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "df = pd.read_csv(\"data/sd_data/metadata.csv\")\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323608"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.loc[df.step >= 1].reset_index(drop=True)\n",
    "df_new.to_csv(\"data/sd_data/metadata_min_step=1.csv\", index=False)\n",
    "df_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing similar filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   1.   0.82 1.   0.58]\n",
      " [1.   0.   0.82 1.   0.58]\n",
      " [0.82 0.82 0.   0.82 0.71]\n",
      " [1.   1.   0.82 0.   0.58]\n",
      " [0.58 0.58 0.71 0.58 0.  ]]\n",
      "(array([0, 0, 1, 1, 3, 3]), array([1, 3, 0, 3, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# embeddings numpy array\n",
    "embeddings = np.array([\n",
    "    [1,1,1],\n",
    "    [1,1,1],\n",
    "    [0,1,1],\n",
    "    [1,1,1],\n",
    "    [0,0,1],\n",
    "])\n",
    "\n",
    "# compute cosine similarity matrix\n",
    "cos_sim_matrix = cosine_similarity(embeddings, embeddings)\n",
    "\n",
    "# set diagonal values to False\n",
    "np.fill_diagonal(cos_sim_matrix, False)\n",
    "\n",
    "# set threshold for cosine similarity score\n",
    "threshold = 0.9\n",
    "\n",
    "# create boolean mask based on threshold\n",
    "sim_mask = cos_sim_matrix >= threshold\n",
    "print(np.round(cos_sim_matrix, 2))\n",
    "\n",
    "# apply boolean masks to get indices of too similar embeddings\n",
    "similar_indices = np.nonzero(sim_mask)\n",
    "ignore_indices = np.unique(np.nonzero(sim_mask)[1])\n",
    "\n",
    "print(similar_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.95\n",
    "bs = 1024\n",
    "n_embeddings = len(embeddings)\n",
    "idxs_to_ignore = set()\n",
    "pbar = tqdm()\n",
    "i = 0\n",
    "while i < n_embeddings:\n",
    "    idxs = []\n",
    "    while len(idxs) < bs and i < n_embeddings:\n",
    "        if i not in idxs_to_ignore:\n",
    "            idxs.append(i)\n",
    "        i += 1\n",
    "    cos_sim = cosine_similarity(embeddings[idxs], embeddings)\n",
    "    np.fill_diagonal(cos_sim, 0)\n",
    "    mask = cos_sim >= thresh\n",
    "    indices_to_drop = []\n",
    "    new_to_ignore = set(np.nonzero(sim_mask)[1])\n",
    "    idxs_to_ignore = idxs_to_ignore.union(new_to_ignore)\n",
    "    \n",
    "    pbar.total = n_embeddings - len(dropped)\n",
    "    pbar.update(len(idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
